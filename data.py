"""
    This file is Pytorch Geometric dataset handling class and methods module.
    --WIP--

    TODO:
        - Implement dense_to_sparse method for multi-graphs
        - Implement real-world dataset classes
        - Implement dataset statistics methods
        ? Seperate package
"""
import os
import os.path as osp
from typing import Tuple

import numpy as np
import torch

from torch_geometric.data import Data, Dataset
from torch_geometric.loader import DataLoader
from torch_geometric.utils import to_dense_adj


def sample_np_to_pyg(multigraph: np.ndarray, node_features: np.ndarray = None,
                     node_labels: np.ndarray = None, flat_mask=None, subject_type=None):
    # multi-graph shape: (l, n, n)
    # node features shape: (n, d)
    # node labels shape: (n,)

    n_nodes = multigraph.shape[-1]
    n_layers = multigraph.shape[0]

    # Allocate numpy arrays
    # edge_index max shape: (2, n_nodes * n_nodes)
    # edge_attr max shape: (n_nodes * n_nodes, n_layers)

    if node_labels is None:
        y = np.zeros((1,))
    else:
        y = node_labels

    # Fill edge index and edge attribute matrices

    con_mat = torch.tensor(multigraph, dtype=torch.float)
    select_multigraph_edges = torch.any(con_mat, dim=0)
    edge_index = select_multigraph_edges.float().nonzero().t().contiguous()
    # TODO: Later check if edge attributes are correct
    edge_attr = con_mat[:, edge_index[0], edge_index[1]].t()
    # _edge_attr = con_mat[:, select_multigraph_edges].t()
    """for i in range(n_nodes):
        for j in range(n_nodes):
            edge_index[:, i * n_nodes + j] = [i, j]
            edge_attr[i * n_nodes + j, :] = multigraph[:, i, j]"""

    # Fill node feature matrix (no features every node is 1)
    if node_features is None:
        x = np.eye(n_nodes)
    else:
        x = node_features

    # Get graph labels
    if node_labels is None:
        y[0] = None

    # TODO: Update this code
    if flat_mask is not None:
        edge_index_masked = []
        edge_attr_masked = []
        for i, val in enumerate(flat_mask):
            if val == 1:
                edge_index_masked.append(edge_index[:, i])
                edge_attr_masked.append(edge_attr[i, :])
        edge_index = np.array(edge_index_masked).T
        edge_attr = edge_attr_masked

    edge_index.to(dtype=torch.long)
    edge_attr.to(dtype=torch.float)

    x = torch.tensor(x, dtype=torch.float)
    y = torch.tensor(y, dtype=torch.float)

    data = Data(x=x, edge_index=edge_index, edge_attr=edge_attr, y=y, label=subject_type)

    return data


class GraphSimulationDataset(Dataset):
    r"""A dataset of graphs readily generated by a simulation model, i.e. SBM, WSBM, etc."""

    def __init__(self, root, transform=None, pre_transform=None, pre_filter=None):
        super().__init__(root, transform, pre_transform, pre_filter)

    @property
    def processed_file_names(self):
        # Crawl processed (root for now) directory and return list of processed files
        # loop over in root directory and return list of files that are .pt
        return [name for name in os.listdir(self.processed_dir)
                if os.path.isfile(os.path.join(self.processed_dir, name)) and
                name.endswith('.pt') and name.__contains__('data_')]

    @property
    def processed_dir(self) -> str:
        # TODO: return processed directory instead of root
        return self.root

    def len(self):
        return len(self.processed_file_names)

    def get(self, idx):
        # FIXME: idx start from 1 atm
        data = torch.load(osp.join(self.processed_dir, f'data_{idx + 1}.pt'))
        return data


def get_dataset(path: str, dataset_type: str, **kwargs):
    # TODO: Would generic dataset class suffice?
    if dataset_type == 'GraphSimulationDataset':
        # [torch.load(os.path.join(path, name)) for name in os.listdir(path) if os.path.isfile(os.path.join(path, name)) and name.endswith('.pt')]
        return GraphSimulationDataset(root=path, **kwargs)
    else:
        # TODO: Implement other dataset types like real-world datasets
        return NotImplemented


def get_dataloaders(dataset, train_idx, test_index, batch_size, generator, **kwargs):
    train_loader = DataLoader(dataset, batch_size=batch_size, sampler=torch.utils.data.SubsetRandomSampler(train_idx),
                              generator=generator, **kwargs)
    test_loader = DataLoader(dataset, batch_size=batch_size, sampler=torch.utils.data.SubsetRandomSampler(test_index),
                             generator=generator, **kwargs)
    return train_loader, test_loader


def get_dataset_stats(dataset: Dataset, idx=None) -> tuple:
    r"""Returns graph channel-wise mean and std of training dataset."""
    if idx is not None:
        loader = DataLoader(dataset, batch_size=len(dataset), sampler=torch.utils.data.SubsetRandomSampler(idx))
    else:
        loader = DataLoader(dataset, batch_size=len(dataset))
    whole_batch = next(iter(loader))
    adj = to_dense_adj(whole_batch.edge_index, edge_attr=whole_batch.edge_attr, batch=whole_batch.batch)
    std, mean = torch.std_mean(adj, dim=(0, 1, 2))

    return mean, std


def dense_to_sparse(adj: torch.tensor) -> Tuple[torch.tensor, torch.tensor, torch.tensor]:
    r"""Converts a dense adjacency matrix to a sparse adjacency matrix defined by edge indices and edge attributes.
        Code solution from: https://github.com/pyg-team/pytorch_geometric/discussions/2628
    Args:
     :param   adj: (Tensor) The dense adjacency matrix.
                    Shape is [B, N, N] or [B, N, N, F] where B is the batch size, N is the number of nodes,
                                                                                and F is the number of edge features.
     :rtype: (:class:`LongTensor`, :class:`Tensor`, :class:`LongTensor`)
    """
    adj_flat = adj.abs().sum(dim=-1)  # Find non-zero edges in `adj` with multidimensional edge_features
    index = adj_flat.nonzero(as_tuple=True)
    edge_attr = adj[index]
    num_nodes = adj.size(-2)
    edge_batch = index[0] * num_nodes
    index = (edge_batch + index[1], edge_batch + index[2])
    edge_index = torch.stack(index, dim=0)
    # NOTE: Check on later
    batch = torch.arange(adj.size(0)).view(-1, 1).repeat(1, num_nodes).view(-1)

    return edge_index, edge_attr, batch
